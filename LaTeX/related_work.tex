% RE approaches are primarily described by two general model classes: sequence-based, and graph-based methods. Sequence-based models infer new relations by applying recurrent neural networks (RNNs) over given sentences containing subjects and objects, whereas graph-based approaches predict relations by additionally utilizing the sentence's dependency tree and subject and object subtree structures via graph convolution networks (GCNs). In a similar manner, KGLP models also primarily comprise of two method classes: single-hop and multi-hop approaches. Complementary to RE sequence-based methods, single-hop methods ignore explicit KG structure by only reasoning over subjects and relations. 
% sequence-based models typically infer relations by applying a recurrent neural network (RNN) over the sentence, and subject and object, followed by an attention mechanism. For instance, PA-LSTM, proposed by \textbf{[CITE]}, learns relations by passing an LSTM over an input sentence, and attending the output via a position-aware attention mechanism. This module weighs each LSTM hidden unit by its respective token's distance from the subject and object. More recently, BERT \textbf{[CITE]}, has been applied on RE tasks to significantly improve performance. \textcolor{red}{BERT-RE} utilize 

There are three areas of research that are related to the method we propose in this paper.
In this section, we discuss related work in each area and position JRRILP appropriately.

\textbf{Relation Extraction.}
Existing RE approaches can be classified in two categories: sequence-based, and graph-based methods.
Given a sentence in the form of a sequence of tokens, sequence-based models infer relations by applying recurrent neural networks \citep{zhou-etal-2016-attention, palstm}, convolutional neural networks \citep{zeng-etal-2014-relation, nguyen-grishman-2015-relation, wang-etal-2016-relation}, or transformers \citep{tre, bert-em}.
In addition to the sentence,
graph-based methods use the structural characteristics of the sentence dependency tree to achieve strong performance. \citep{peng2017} apply an n-ary Tree-LSTM \citep{treelstm} over a split dependency tree, while \citep{cgcn, aggcn} employ a graph-convolution network (GCN) over the dependency tree.

\textbf{Knowledge Graph Link Prediction.}
Existing KGLP approaches broadly fall under two model classes: single-hop and multi-hop.
Given a subject and a relation, single-hop models infer a set of objects by mapping the subject and relation respectively to unique learnable finite dimensional vectors (embeddings) and jointly transforming them to produce an object set. These approaches can be translational \citep{bordes2013translating} over the embeddings, multiplicative \citep{yang2015embedding, trouillon2016complex}, or a combination of the two
\citep{dettmers2018conve, transr_ctranr, transd, tucker, coper, GAAT}.
% (\citep{dettmers2018conve}, \citep{transr_ctranr}, \citep{transd}, \citep{tucker}).
On the other hand, multi-hop approaches determine object sets by finding paths in the KG connecting subjects to the objects, and primarily consist of path-ranking methods 
\citep{lao2011random, gardner2013improving, neelakantancompositional, guutraversing, toutanova2016compositional, minerva, salesforce}.

% Several approaches \citep{weston-2013, han, lfds, long_tail, bag_re_kglp} have explored using the additional supervision provided by a KG to benefit relation extraction model performance. Of these, we believe \citep{weston-2013, han, lfds} are most similar to our work. \citep{weston-2013} propose a framework which utilizes a KGLP model, TransE \citep{bordes2013translating}, as an additional confidence measure when evaluating a RE approach's performance. TransE estimates the confidence in a predicted object by computing its distance to the vector-sum of the subject and relation embeddings. Re-interpreting this measure as the distance of a relation to the vector-difference of the object and subject, TransE can measure the similarity of a RE model's predicted relation to the expected relation. While adjoining this method to a RE model's prediction aids performance, it suffers from two limitations: (1) The KGLP and RE models are trained separately, and only interact with each other at inference. (2) The learned subject, object and relation embeddings between the RE and KGLP approach are not shared. Thus, the framework only enables information sharing during evaluation, excluding the models' ability to communicate with and benefit from each other during training. \citep{han} proposes a dual-attention framework for jointly learning KGLP and RE tasks by computing a weight distribution over training data. While this approach exhibits the notable benefits of parameter sharing -- including subject, object and relation representations -- between tasks, it presents a strict constraint on the type of KGLP models supported. Specifically, like \citep{weston-2013}, \citep{han} only supports KGLP methods can be reframed as predicting relations from subjects and objects. While several KGLP methods satisfy this criterion, many recent approaches {\em cannot} be transformed in this way. \citep{lfds} also presents a joint framework, LFDS, for training relation extraction approaches via KGLP models. In particular, the architecture introduces a similar objective to $\mathcal{L}_3$, but can only support the same class of KGLP methods as in \citep{weston-2013, han}. Similar to JRRILP, this approach shares the subject and object embeddings between tasks. However, LFDS suffers from two limitations: (1) like $\mathcal{L}_3$, relation representations are not jointly trained with the other parameters. Instead, the relation embeddings are pre-trained on TransE and only interact with the RE method during evaluation. This introduces a possible domain-shift between the predicted RE relations and the pretrained relation embeddings.
% (2) LFDS restricts the valid KGLP model space to equivalent types of methods as in \citep{weston-2013}
% and \citep{han}.

\textbf{Joint Frameworks.}
Several approaches  \citep{weston-2013, han, lfds, long_tail, bag_re_kglp} have explored using the additional supervision provided by a KG to benefit relation extraction model performance. Of these, we believe \citep{weston-2013, han, lfds} are most similar to our work. \citep{weston-2013} proposes a framework which utilizes a KGLP model, TransE \citep{bordes2013translating}, as an additional re-ranking term when evaluating an RE model. While employing TransE as a re-ranker improves performance, their framework trains TransE and the respective RE approach separately without parameter sharing. This only allows very restricted information sharing during evaluation.
\citep{han} proposes a dual-attention framework for jointly learning KGLP and RE tasks by computing a weight distribution over training data and shares parameters between tasks. However, like \citep{weston-2013}, \citep{han} limits KGLP model selection to those which can reformulated as inferring relations from subjects and objects. This excludes a large number of recent methods \citep[e.g.,][]{dettmers2018conve, tucker, minerva, salesforce, coper, GAAT} which cannot be reframed in this way. \citep{lfds} also presents a joint framework, LFDS, for training relation extraction approaches via KGLP objectives. In particular, the architecture introduces a similar objective to $\mathcal{L}_{\text{COUPLING}}$, but can only support the same class of KGLP methods as in \citep{weston-2013, han}. Moreover, LFDS requires KGLP pre-training, and does not share core parameters such as relation representations between RE and KGLP methods. This can create domain-shift between the two respective models and impact performance.

% JRRILP improves upon previous literature by addressing their limitations.
% Concretely, JRRILP proposes an abstract multi-task learning framework which jointly learns RE and KGLP objectives through unconstrained inter-task information sharing. JRRILP facilitates this by jointly reasoning over three tasks. Similar to \citep{weston-2013}, the first two tasks involve training a RE and KGLP model over their respective objectives. However, in contrast to \citep{weston-2013}, JRRILP fully supports many existing relation extraction approaches {\em and} many existing KGLP models. Importantly, JRRILP satisfies the latter by proposing a KGLP objective covers arbitrary existing models.
% Secondly, JRRILP trains both tasks jointly from scratch. This not only eliminates the need to pre-train KGLP methods, but also exhibits the benefit of sharing subject/object and relation embeddings between tasks. Based off \citep{lfds}, the third task involves training the composition of the RE and KGLP models over the KGLP objective. While this task is superficially equivalent to LFDS, the presence of the first two tasks, $\mathcal{L}_1$ and $\mathcal{L}_2$, ameliorate its most notable drawback: by jointly training both models' parameters, the possible domain shift between learned KGLP relation embeddings and learned RE embeddings is eliminated. Moreover, $\mathcal{L}_1$ and $\mathcal{L}_2$ establish a cyclic connection between RE and KGLP tasks and enhances RE method performance.
% Additionally, JRRILP's abstract architecture enables it to support any existing RE approach and many KGLP models with minimal implementation changes.

JRRILP improves upon previous literature by providing a single joint objective which simultaneously addresses all their aforementioned limitations. First, JRRILP proposes an abstract framework which supports many RE and KGLP methods through three standard-based loss terms. Second, JRRILP shares all its parameters between KGLP and RE tasks, and establishes a novel cyclical learning structure over core parameters. Third, RE and KGLP tasks are jointly trained without any problem-specific pretraining required, enabling tasks to benefit from each other simultaneously during training. Fourth, JRRILP's structure facilitates suport for RE and KGLP methods with minimal implementation changes: only requiring their respective substitutions into $f$ and $g$.

% Perhaps the most salient difference between JRRILP and previous work is that while prior methods enhance RE model performance by extending both its training and evaluation framework, JRRILP {\em only} integrates KGLP in the training phase. Crucially, this means that strong performance is dependent only on the RE model's learned representations and parameters -- KGLP methods bear no influence during evaluation. This means that while previous frameworks augments RE approaches by increased model capacity, JRRILP enhances them by altering their training trajectories to better optima. 

% MENTION: Does not require access to dataset with KG. Instead, KG is computed on the fly <-- only uses information available in the singular dataset!!!!! 

% inferring relations in one domain with relations from the other
%   - 